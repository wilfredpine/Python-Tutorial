{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform a search using the full prompt, especially without relying on basic keyword matching, you can use Natural Language Processing (NLP) techniques to find the most relevant documents. One effective approach is to use embedding-based semantic search, which leverages vector representations of text. Here's how it can be done:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution Overview\n",
    "\n",
    "    - Embed each document in your docs list and the query.\n",
    "    - Compare the query embedding with each document's embedding to find the most relevant ones.\n",
    "    - Retrieve the documents that are most similar to your query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some steps to implement this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install Sentence Transformers for easy text embedding generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''pip install sentence-transformers'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Embeddings for documents and query.\n",
    "\n",
    "Use a pre-trained model like `sentence-transformers` to convert each document and the query into vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Similarity between the query vector and each document vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the Most Relevant Documents based on similarity scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\nlp\\nlpenv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "d:\\Projects\\nlp\\nlpenv\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\WVP\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents related to your query:\n",
      "This document covers basics of NLP and its applications.\n",
      "This is an overview of NLP techniques in text summarization.\n",
      "NLP models are being used to improve customer support experiences.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # This model is efficient and accurate for semantic similarity\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    'This document covers basics of NLP and its applications.',\n",
    "    'IoT systems are expanding rapidly in the tech world.',\n",
    "    'This is an overview of NLP techniques in text summarization.',\n",
    "    'Artificial Intelligence in healthcare is transforming the industry.',\n",
    "    'NLP models are being used to improve customer support experiences.'\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"Give me all documents about NLP.\"\n",
    "\n",
    "# Step 1: Generate embeddings for each document\n",
    "doc_embeddings = model.encode(docs)\n",
    "\n",
    "# Step 2: Generate embedding for the query\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "# Step 3: Compute cosine similarity between the query and each document\n",
    "similarities = util.cos_sim(query_embedding, doc_embeddings)[0]  # [0] to get the row array\n",
    "\n",
    "# Step 4: Retrieve documents with high similarity scores\n",
    "# Convert to list and get indices of top matches (e.g., similarity > threshold)\n",
    "threshold = 0.4  # Define a threshold for relevance\n",
    "relevant_docs = [docs[i] for i in np.where(similarities > threshold)[0]]\n",
    "\n",
    "# Print results\n",
    "print(\"Relevant documents related to your query:\")\n",
    "for doc in relevant_docs:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevant documents related to your query:\n",
      "Title: IoT System. Introduction: IoT systems are expanding rapidly in the tech world. Date: June 3, 2023\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load a pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # This model is efficient and accurate for semantic similarity\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    'Title: NLP Integration. Introduction: This document covers basics of NLP and its applications. Date: April 9, 2024',\n",
    "    'Title: IoT System. Introduction: IoT systems are expanding rapidly in the tech world. Date: June 3, 2023',\n",
    "    'Title: NLP Techniques. Introduction: This is an overview of NLP techniques in text summarization. Date: July 12, 2024',\n",
    "    'Title: AI in Health. Introduction: Artificial Intelligence in healthcare is transforming the industry. December 12, 2021',\n",
    "    'Title: NLP Models. Introduction: NLP models are being used to improve customer support experiences. December 1, 2020'\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"Give me the document entitled: IoT System.\"\n",
    "\n",
    "# Step 1: Generate embeddings for each document\n",
    "doc_embeddings = model.encode(docs)\n",
    "\n",
    "# Step 2: Generate embedding for the query\n",
    "query_embedding = model.encode(query)\n",
    "\n",
    "# Step 3: Compute cosine similarity between the query and each document\n",
    "similarities = util.cos_sim(query_embedding, doc_embeddings)[0]  # [0] to get the row array\n",
    "\n",
    "# Step 4: Retrieve documents with high similarity scores\n",
    "# Convert to list and get indices of top matches (e.g., similarity > threshold)\n",
    "threshold = 0.4  # Define a threshold for relevance\n",
    "relevant_docs = [docs[i] for i in np.where(similarities > threshold)[0]]\n",
    "\n",
    "# Print results\n",
    "print(\"Relevant documents related to your query:\")\n",
    "for doc in relevant_docs:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Search or Year Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Years found in query: [2020, 2023]\n",
      "Relevant documents based on years in the query:\n",
      "Title: IoT System. Introduction: IoT systems are expanding rapidly in the tech world. Date: June 3, 2023\n",
      "Title: NLP Models. Introduction: NLP models are being used to improve customer support experiences. December 1, 2020\n",
      "Relevant documents related to your query:\n",
      "Title: NLP Models. Introduction: NLP models are being used to improve customer support experiences. December 1, 2020\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Title: NLP Models. Introduction: NLP models are being used to improve customer support experiences. December 1, 2020']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# Load a pre-trained model for generating embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # This model is efficient and accurate for semantic similarity\n",
    "\n",
    "# Function to extract years from the query\n",
    "def extract_years_from_query(query):\n",
    "    years = re.findall(r'\\b(20\\d{2})\\b', query)  # Finds all four-digit numbers starting with '20'\n",
    "    return [int(year) for year in years] if years else None  # Convert to integers for easier processing\n",
    "\n",
    "def semantic_search(docs,query):\n",
    "    # Semantic Search\n",
    "    # Step 1: Generate embeddings for each document\n",
    "    doc_embeddings = model.encode(docs)\n",
    "    # Step 2: Generate embedding for the query\n",
    "    query_embedding = model.encode(query)\n",
    "    # Step 3: Compute cosine similarity between the query and each document\n",
    "    similarities = util.cos_sim(query_embedding, doc_embeddings)[0]  # [0] to get the row array\n",
    "    # Step 4: Retrieve documents with high similarity scores\n",
    "    # Convert to list and get indices of top matches (e.g., similarity > threshold)\n",
    "    threshold = 0.4  # Define a threshold for relevance\n",
    "    relevant_docs = [docs[i] for i in np.where(similarities > threshold)[0]]\n",
    "\n",
    "    # Print results\n",
    "    print(\"Relevant documents related to your query:\")\n",
    "    for doc in relevant_docs:\n",
    "        print(doc)\n",
    "        \n",
    "    return relevant_docs\n",
    "\n",
    "def search(docs,query):\n",
    "    # Extract years\n",
    "    years_in_query = extract_years_from_query(query)\n",
    "    # Output results\n",
    "    if years_in_query:\n",
    "        print(\"Years found in query:\", years_in_query)\n",
    "        # Filter documents that contain any of the years found in the query\n",
    "        filtered_docs = [\n",
    "            doc for doc in docs\n",
    "            if any(str(year) in doc for year in years_in_query)  # Check if any year is in the document text\n",
    "        ]\n",
    "        \n",
    "        print(\"Relevant documents based on years in the query:\")\n",
    "        for doc in filtered_docs:\n",
    "            print(doc)\n",
    "    \n",
    "        # search again using query\n",
    "        result = semantic_search(filtered_docs,query)\n",
    "        if not result:\n",
    "            return filtered_docs\n",
    "        else:\n",
    "            return result\n",
    "    else:\n",
    "        print(\"No years found in query.\")\n",
    "        return semantic_search(filtered_docs,query)\n",
    "\n",
    "\n",
    "# Example documents\n",
    "docs = [\n",
    "    'Title: NLP Integration. Introduction: This document covers basics of NLP and its applications. Date: April 9, 2024',\n",
    "    'Title: IoT System. Introduction: IoT systems are expanding rapidly in the tech world. Date: June 3, 2023',\n",
    "    'Title: NLP Techniques. Introduction: This is an overview of NLP techniques in text summarization. Date: July 12, 2024',\n",
    "    'Title: AI in Health. Introduction: Artificial Intelligence in healthcare is transforming the industry. December 12, 2021',\n",
    "    'Title: NLP Models. Introduction: NLP models are being used to improve customer support experiences. December 1, 2020'\n",
    "]\n",
    "\n",
    "# Query\n",
    "query = \"Give me all documents using NLP at 2020 and 2023.\"\n",
    "\n",
    "search(docs,query)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
